
# ONE BIRD-TWO NEURAL NETWORK

AFTER  IMPORTING ALL THE NECESSARY LIBRARIES, TWO PYTHON FILES MADE CVAE_EXP AND CVAE_function. 
THE FORMER CONTAINS THE AUTOENCODER ARCHITECTURE, AND THE LATTER CONTAINS VARIOUS METHODS TO CALCULATE THE LOSS FUNCTION TO TRAIN, TEST AND GENERATE SAMPLES.






## LOSS FUNCTION       

THE KL DIVERGENCE LOSS FUNCTION WAS MAINTAINED THE SAME, i.e. -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())  I USED THE HUBER LOSS FUNCTION FOR THE RECONSTRUCTED ERROR.
 ![image](https://github.com/likithxlr804/One-bird--two-neural-network-challenge/assets/134731735/93e5aa00-a872-420a-930e-e12c854e0674)


THE HUBER LOSS FUNCTION RESEMBLES THE MEAN ABSOLUTE LOSS(MAE) FOR HIGHER VALUES AND MEAN SQUARED LOSS(MSE) FOR SMALL VALUES; HENCE THIS FUNCTION HELPS BETTER IN HANDLING OUTLIERS IN DATA.


## HYPERPARAMETER TUNING USING OPTUNA

OPTUNA USES BAYESIAN SEARCH TO FIND THE OPTIMAL HYPERPARAMETERS FOR THE GIVEN OBJECTIVE FUNCTION. ALONG WITH BAYESIAN SEARCH, IT ALSO EMPLOYS TREE-STRUCTURED PARZEN. 
FIRSTLY, WE DEFINE OUR OBJECTIVE FUNCTION, WHICH ALSO HAS TRIAL AS AN ARGUMENT( TO DISPLAY THE INFORMATION AFTER EACH TRIAL). IN OUR OBJECTIVE FUNCTION, HYPERPARAMETERS SUCH AS LR, WEIGHTS OF RESPECTIVE LOSSES, OPTIMIZER,WEIGHT DECAY,BATCH SIZE AND EPOCHS NEED TO BE TUNED. 
HENCE,  THE RANGE IN WHICH THESE HYPERPARAMETERS SHOULD FALL IS INPUTED BY THE USER IN THE FORM OF A DICTIONARY.

OUR OBJECTIVE FUNCTION CONSISTS OF THE MODEL CVAE.CVAE() AND THE DATALOADER IS THE TRAINING DATASET AND THE TRIAL.

DURING EACH TRIAL, A SURROGATE MODEL IS PREPARED FROM THE EXISTING PARAMETERS, AND THEN THE BAYESIAN SEARCH USES AN EXPECTED IMPROVEMENT ALGORITHM TO FIND THE NEXT BEST FIT.

WE OPTIONED THREE OPTIMIZERS( ADAM, RMSprop, SGD) OUT OF WHICH THE OPTIMAL ONE WOULD BE DEPLOYED IN THE MODEL. WE HAVE ALSO USED WEIGHT_DECAY TO MANAGE THE ISSUE OF OVERFITTING.
LATER, A STUDY IS CREATED BY OPTUNA WHERE THE TRIALS ARE RUN, AND THE STUDY MINIMISES.

 ** beta*epoch_result["KLD_loss"]+wx*epoch_result["x_loss"]+wy*epoch_result["y_loss"] ** 


NOW, THE OBTAINED HYPERPARAMETERS FROM THE MODEL ARE USED TO TRAIN OUR DATALOADER AND VALIDATE USING THE VALIDATION DATESET.

THEN, SAMPLES FROM THE DATALOADER WERE PLOTTED TO VISUALIZE THE RESULTS.

# RESULTS

## DATA_1

![Screenshot (5)](https://github.com/likithxlr804/One-bird--two-neural-network-challenge/assets/134731735/5d9a1477-e0a6-422f-8b32-c131f0c57b21)

## DATA_2
![Screenshot (18)](https://github.com/likithxlr804/One-bird--two-neural-network-challenge/assets/134731735/a6416fdc-4ef1-48a0-9019-3c9d8f55b131)


![Screenshot (20)](https://github.com/likithxlr804/One-bird--two-neural-network-challenge/assets/134731735/b3fc99c2-b9ef-4b2e-99c2-d827c84a204f)

## DATA_ORIGINAL

![Screenshot (13)](https://github.com/likithxlr804/One-bird--two-neural-network-challenge/assets/134731735/ca20b7d3-9d5b-4b5d-bb96-f497923315ec)








